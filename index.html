<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Dynamic Token Selection for Aerial-Ground Person Re-Identification">
  <meta name="keywords" content="Token Selection, Re-Identification">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Dynamic Token Selection for Aerial-Ground Person Re-Identification</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./favicon.ico">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://yuhaiw.github.io/">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://sope-dex.github.io/">
            SOPE
          </a>
          <a class="navbar-item" href="https://arxiv.org/pdf/2405.02880">
            Distributed-NeRF
          </a>
          <a class="navbar-item" href="https://www.bilibili.com/video/BV1LR4y1x7ad/?share_source=copy_web">
            ARX-Arm
          </a>
          <a class="navbar-item" href="https://youtu.be/mtlygIGOYEE?si=aOASBgGjbCKs6AGp">
            Lyway
          </a>
        </div>
      </div>
    </div>

  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Dynamic Token Selection for Aerial-Ground Person Re-Identification</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://yuhaiw.github.io/">Yuhai Wang</a><sup>*</sup>,</span>
            <span class="author-block">
              <a href="https://viterbi.usc.edu/directory/faculty/Pishgar/Maryam">Maryam Pishgar</a><sup></sup></span>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup></sup><b>University of Southern California</b></span>
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup></sup></span>
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>*</sup>Corresponding Author</span>
          </div>
          
          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup></sup>IEEE International Conference on Multimedia & Expo(ICME) 2025</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="ICMEYuhai.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2412.00433"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/YuhaiW/reidselecttoken"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="https://drive.google.com/file/d/1yDjyH0VtW7efxP3vgQjIqTx2oafCB67t/view"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- main video -->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video id="teaser" autoplay muted loop playsinline height="100%">
        <source src="./static/videos/overview.mp4"
                type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        Showing the  architecture of Dynamic Token Selective Transformer and Visual Token Selector.
      </h2>
    </div>
  </div>
</section>


<!-- Abstract. -->
<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Aerial-Ground Person Re-identification (AGPReID) holds significant practical value 
            but faces unique challenges due to pronounced variations in viewing angles, 
            lighting conditions, and background interference.Traditional methods, 
            often involving a global analysis of the entire image, 
            frequently lead to inefficiencies and susceptibility to irrelevant data. 
          </p>
          <p>
            In this paper, we propose a novel Dynamic Token Selective Transformer (DTST) tailored for AGPReID, 
            which dynamically selects pivotal tokens to concentrate on pertinent regions.
          </p>
          <p>
            Specifically, we segment the input image into multiple tokens, 
            with each token representing a unique region or feature within the image. 
            Using a Top-k strategy, we extract the k most significant tokens 
            that contain vital information essential for identity recognition. 
            Subsequently, an attention mechanism is employed to discern interrelations among diverse tokens, 
            thereby enhancing the representation of identity features. 
            Extensive experiments on benchmark datasets showcases the superiority of our method over existing works. 
            Notably, on the CARGO dataset, our proposed method gains 1.18% mAP improvements 
            when compared to the second place. 
            In addition, we comprehensively analyze the impact of different numbers of tokens, 
            token insertion positions, and numbers of heads on model performance.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  <!-- Paper video. -->
  <div class="columns is-centered has-text-centered">
    <div class="column is-four-fifths">
      <h2 class="title is-3">Experimental Validation Video</h2>
      <div class="publication-video">
        <iframe width="560" height="315" src="https://www.youtube.com/embed/hYg_d6rCAJs?si=A2cSc5EEX8A3M3_k" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
      </div>
    </div>
  </div>
  
  <!--/ Paper video. -->

  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Approch</h2>
        <div class="content has-text-justified">
          <p>
            We propose the Dynamic Token Selective Transformer <b>(DTST)</b> based on the View-Decoupled Transformer (VDT) to tackle the view discrepancy challenge in AGPReID. 
            Input images that include both aerial and ground views are tokenized into a sequence of tokens. 
            To encompass both global and view-specific details, meta tokens and view tokens are added to these image tokens before they are inputted into the VDT.
          </p>
          <p>
            We also introduce the Visual Token Selector <b>(VTS)</b> to each VDT blocks, 
            designed to dynamically refine the token representation by selecting the most informative tokens 
            for subsequent analysis. This module aims to reduce redundancy and enhance the model's ability 
            to focus on critical regions, thereby optimizing computational efficiency while preserving feature 
            quality. The VTS mechanism can be understood as a dynamic token selection process that 
            leverages attention scores to determine the importance of each token. 
          </p>
          <p>
            The following figures illustrate the architecture of the proposed DTST and DTS.
          </p>
        </div>
      </div>
    </div>


  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
    

      <!-- Visual Effects. -->
      <div class="column">
        <div class="content">
          <!-- <h3 class="title is-3">DTST Overview</h3> -->
          <h3 class="title is-4">DTST Overview</h3>
          <p>
            The framework incorporates N Token Selection VDT blocks, 
            where each block consists of an encoder layer and a visual token selector. 
            The loss function is designed to account for both view-related and view-unrelated features, 
            while an orthogonal loss ensures that these features remain independent from each other, 
            further enhancing feature disentanglement and robustness.
          </p>
          <picture>
            <source srcset="./static/images/sub_overview.png" type="image/png">
            <img src="./static/images/sub_overview.png" alt="DTST Overview" style="width: 100%;"/>
          </picture>
          <!-- <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/dollyzoom-stacked.mp4"
                    type="video/mp4">
          </video> -->
        </div>
      </div>
      <!--/ Visual Effects. -->

      <!-- Matting. -->
      <div class="column">
        <h3 class="title is-4">VTS Overview</h3>
        
        <div class="columns is-centered">
          <div class="column content">
            <p>
              Designed to dynamically refine the token representation 
              by selecting the most informative tokens for subsequent analysis. 
              This module aims to reduce redundancy and enhance the model's ability to focus on critical regions, 
              thereby optimizing computational efficiency while preserving feature quality.
            </p>
            <!-- <video id="matting-video" controls playsinline height="100%">
              <source src="./static/videos/matting.mp4"
                      type="video/mp4">
            </video> -->
            <picture>
              <source srcset="./static/images/VTS.png" type="image/png">
              <img src="./static/images/VTS.png" alt="Visual Token Selector" style="width: 100%;"/>
          </div>

        </div>
      </div>
    </div>
    <!--/ Matting. -->



  </div>
</section>

    <!-- Result. -->
<section class="section">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">

          <h2 class="title is-3">Experiments</h2>
          <p>
            We evaluate the proposed DTST on three benchmark datasets: CARGO, AG-ReID.
          </p>
          <p>
            The results demonstrate that our method outperforms existing works in terms of mAP and rank-1 accuracy.
          </p>
          <!-- a blank line -->
          <br>
          <h3 class="title is-4">1. CARGO Result</h3>
          <picture>
            <source srcset="./static/images/main_result.png" type="image/png">
            <img src="./static/images/main_result.png" alt="main_result" style="width: 70%;"/>
          </picture>
          <br>
          <br>
          <h3 class="title is-4">2. AG-ReID Result</h3>
          <picture>
            <source srcset="./static/images/AG_Result.png" type="image/png">
            <img src="./static/images/AG_Result.png" alt="AG_Result" style="width: 40%;"/>
          </picture>

        
      </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{wang2024dynamic,
      title={Dynamic Token Selection for Aerial-Ground Person Re-Identification},
      author={Wang, Yuhai and Pishgar, Maryam},
      journal={arXiv preprint arXiv:2412.00433},
      year={2024}
    }</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="https://arxiv.org/pdf/2412.00433">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/YuhaiW" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            Inspired by <a
              href="https://github.com/nerfies/nerfies.github.io">nerfies's website</a>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
